{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m venv myenv\n",
    "# source myenv/bin/activate  # On Windows use `myenv\\Scripts\\activate`\n",
    "#!pip install lmqg\n",
    "# python -m spacy download en_core_web_sm\n",
    "from pprint import pprint\n",
    "from lmqg import TransformersQG\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"./evaluate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:671: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1033: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\transformers\\modeling_utils.py:2570: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\transformers\\utils\\hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = TransformersQG('lmqg/t5-base-squad-qag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 501.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Who was an English painter who specialised in watercolour landscapes?',\n",
      "  'William Turner'),\n",
      " ('What is William Turner often known as?',\n",
      "  'William Turner of Oxford or just Turner of Oxford'),\n",
      " (\"What did many of Turner's paintings depict?\",\n",
      "  'the countryside around Oxford'),\n",
      " (\"What is one of Turner's best known pictures?\",\n",
      "  'a view of the city of Oxford from Hinksey Hill')]\n"
     ]
    }
   ],
   "source": [
    "context = \"William Turner was an English painter who specialised in watercolour landscapes. He is often known \" \\\n",
    "          \"as William Turner of Oxford or just Turner of Oxford to distinguish him from his contemporary, \" \\\n",
    "          \"J. M. W. Turner. Many of Turner's paintings depicted the countryside around Oxford. One of his \" \\\n",
    "          \"best known pictures is a view of the city of Oxford from Hinksey Hill.\"\n",
    "# model prediction\n",
    "question_answer = model.generate_qa(context)\n",
    "pprint(question_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['qa']\n",
      "[('context', 'qa', 'qag')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:671: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1033: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\transformers\\modeling_utils.py:2570: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\transformers\\utils\\hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from lmqg import GridSearcher\n",
    "trainer = GridSearcher(\n",
    "    checkpoint_dir='tmp_ckpt',\n",
    "    dataset_path=\"./test_pipeline.csv\",\n",
    "    input_types= \"context\",\n",
    "    output_types= \"qa\",\n",
    "    prefix_types = \"qag\",\n",
    "    model='lmqg/t5-base-squad-qag',\n",
    "    max_length=512,\n",
    "    max_length_output=256,\n",
    "    epoch=2,\n",
    "    batch=8,\n",
    "    n_max_config=5,\n",
    "    gradient_accumulation_steps=[8], \n",
    "    lr=[1e-04],\n",
    "    label_smoothing=[0.15],\n",
    "    random_seed=1,\n",
    "    fp16=False\n",
    ")\n",
    "out = trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\j\\\\github\\\\lm-question-generation'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"./train.csv\")[:1000]\n",
    "\n",
    "train.to_csv(\"./test_pipeline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\datasets\\load.py:2088: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from lmqg import data\n",
    "dataset = data.get_dataset(path=\"lmqg/qag_squad\",input_type=\"paragraph\",output_type=\"questions_answers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\j\\\\github\\\\lm-question-generation'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmqg.data import get_dataset\n",
    "\n",
    "dataset = get_dataset(\"./test_pipeline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>context</th>\n",
       "      <th>answer</th>\n",
       "      <th>is_impossible</th>\n",
       "      <th>question</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NEW DELHI , India -LRB- CNN -RRB- -- A high co...</td>\n",
       "      <td>19</td>\n",
       "      <td>False</td>\n",
       "      <td>What was the amount of children murdered ?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-LRB- CNN -RRB- -- Fighting in the volatile Su...</td>\n",
       "      <td>Sudanese region of Darfur</td>\n",
       "      <td>False</td>\n",
       "      <td>Where was one employee killed ?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Johannesburg -LRB- CNN -RRB- -- Miffed by a vi...</td>\n",
       "      <td>Archbishop Desmond Tutu</td>\n",
       "      <td>False</td>\n",
       "      <td>who did say South Africa did not issue a visa ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-LRB- CNN -RRB- -- England international footb...</td>\n",
       "      <td>29-year-old</td>\n",
       "      <td>False</td>\n",
       "      <td>How many years old was the businessman ?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>BAGHDAD , Iraq -LRB- CNN -RRB- -- At least 6,0...</td>\n",
       "      <td>a series of killings and threats by Muslim ext...</td>\n",
       "      <td>False</td>\n",
       "      <td>What frightened the families ?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>995</td>\n",
       "      <td>995</td>\n",
       "      <td>JENA , Louisiana -LRB- CNN -RRB- -- Charges ag...</td>\n",
       "      <td>how authorities handled the cases against Purv...</td>\n",
       "      <td>False</td>\n",
       "      <td>What was the protest in September about ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>996</td>\n",
       "      <td>996</td>\n",
       "      <td>-LRB- CNN -RRB- -- Academy Award-winning compo...</td>\n",
       "      <td>1963 and 1966</td>\n",
       "      <td>False</td>\n",
       "      <td>When was he active ?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>997</td>\n",
       "      <td>997</td>\n",
       "      <td>-LRB- Mental Floss -RRB- -- 1 . Bobby Murcer '...</td>\n",
       "      <td>serving three life sentences</td>\n",
       "      <td>False</td>\n",
       "      <td>WHERE IS THE `` RAINBOW MAN '' NOW ?</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>998</td>\n",
       "      <td>-LRB- CNN -RRB- -- `` Shh ... shh get back , '...</td>\n",
       "      <td>Pearl</td>\n",
       "      <td>False</td>\n",
       "      <td>What island is a 20 minute flight from Panama ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td>999</td>\n",
       "      <td>-LRB- The Frisky -RRB- -- Natalie Portman is g...</td>\n",
       "      <td>No Strings Attached</td>\n",
       "      <td>False</td>\n",
       "      <td>what is coming before the oscars</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0  \\\n",
       "0               0             0           0   \n",
       "1               1             1           1   \n",
       "2               2             2           2   \n",
       "3               3             3           3   \n",
       "4               4             4           4   \n",
       "..            ...           ...         ...   \n",
       "995           995           995         995   \n",
       "996           996           996         996   \n",
       "997           997           997         997   \n",
       "998           998           998         998   \n",
       "999           999           999         999   \n",
       "\n",
       "                                               context  \\\n",
       "0    NEW DELHI , India -LRB- CNN -RRB- -- A high co...   \n",
       "1    -LRB- CNN -RRB- -- Fighting in the volatile Su...   \n",
       "2    Johannesburg -LRB- CNN -RRB- -- Miffed by a vi...   \n",
       "3    -LRB- CNN -RRB- -- England international footb...   \n",
       "4    BAGHDAD , Iraq -LRB- CNN -RRB- -- At least 6,0...   \n",
       "..                                                 ...   \n",
       "995  JENA , Louisiana -LRB- CNN -RRB- -- Charges ag...   \n",
       "996  -LRB- CNN -RRB- -- Academy Award-winning compo...   \n",
       "997  -LRB- Mental Floss -RRB- -- 1 . Bobby Murcer '...   \n",
       "998  -LRB- CNN -RRB- -- `` Shh ... shh get back , '...   \n",
       "999  -LRB- The Frisky -RRB- -- Natalie Portman is g...   \n",
       "\n",
       "                                                answer  is_impossible  \\\n",
       "0                                                   19          False   \n",
       "1                            Sudanese region of Darfur          False   \n",
       "2                              Archbishop Desmond Tutu          False   \n",
       "3                                          29-year-old          False   \n",
       "4    a series of killings and threats by Muslim ext...          False   \n",
       "..                                                 ...            ...   \n",
       "995  how authorities handled the cases against Purv...          False   \n",
       "996                                      1963 and 1966          False   \n",
       "997                       serving three life sentences          False   \n",
       "998                                              Pearl          False   \n",
       "999                                No Strings Attached          False   \n",
       "\n",
       "                                              question  fold  \n",
       "0           What was the amount of children murdered ?     2  \n",
       "1                      Where was one employee killed ?     2  \n",
       "2    who did say South Africa did not issue a visa ...     4  \n",
       "3             How many years old was the businessman ?     2  \n",
       "4                       What frightened the families ?     4  \n",
       "..                                                 ...   ...  \n",
       "995          What was the protest in September about ?     1  \n",
       "996                               When was he active ?     2  \n",
       "997               WHERE IS THE `` RAINBOW MAN '' NOW ?     3  \n",
       "998  What island is a 20 minute flight from Panama ...     1  \n",
       "999                   what is coming before the oscars     4  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./test_pipeline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"./test_pipeline.csv\")[:2].to_csv(\"./test_pipeline2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-11-27 11:32:45 INFO     generate qa for split test\n",
      "2023-11-27 11:32:45 INFO     found 0 empty prediction from 2\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1977.51it/s]\n",
      "2023-11-27 11:32:50 INFO     found 0 empty prediction from 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.56 seconds, 5.76 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 89.95it/s]\n",
      "2023-11-27 11:32:55 INFO     found 0 empty prediction from 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.53 seconds, 5.87 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 221.83it/s]\n",
      "2023-11-27 11:33:00 INFO     found 0 empty prediction from 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.48 seconds, 6.10 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "2023-11-27 11:33:01 INFO     found 0 empty prediction from 2\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "2023-11-27 11:33:01 INFO     found 0 empty prediction from 2\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.82it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 167.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.13 seconds, 0.94 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.06it/s]\n",
      "2023-11-27 11:33:08 INFO     generate qa for split validation\n",
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:671: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1033: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\transformers\\modeling_utils.py:2570: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\transformers\\utils\\hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "2023-11-27 11:33:14 INFO     use spaCy answer extraction model: positionrank\n",
      "2023-11-27 11:33:15 INFO     Model `lmqg/t5-large-squad-qag`\n",
      "2023-11-27 11:33:15 INFO     \t * Num of GPU in use: 0\n",
      "2023-11-27 11:33:15 INFO     \t * Prefix: True\n",
      "2023-11-27 11:33:15 INFO     \t * Language: en (ignore at the training phase)\n",
      "2023-11-27 11:33:16 INFO     model prediction: (qag model)\n",
      "2023-11-27 11:33:16 INFO     running model for `question_answer_pair_generation`\n",
      "2023-11-27 11:33:16 INFO     encode all the data       : 2\n",
      "100%|██████████| 2/2 [00:00<00:00, 226.59it/s]\n",
      "2023-11-27 11:33:16 INFO     after remove the overflow : 2\n",
      "2023-11-27 11:34:14 INFO     found 0 empty prediction from 2\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 198.44it/s]\n",
      "2023-11-27 11:34:18 INFO     found 0 empty prediction from 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.46 seconds, 6.18 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 249.56it/s]\n",
      "2023-11-27 11:34:23 INFO     found 0 empty prediction from 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.47 seconds, 6.13 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 236.35it/s]\n",
      "2023-11-27 11:34:27 INFO     found 0 empty prediction from 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.43 seconds, 6.29 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "2023-11-27 11:34:28 INFO     found 0 empty prediction from 2\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "2023-11-27 11:34:28 INFO     found 0 empty prediction from 2\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.13 seconds, 0.94 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.95it/s]\n"
     ]
    }
   ],
   "source": [
    "from lmqg.lmqg_cl.qag_evaluation import run_evaluation\n",
    "\n",
    "args_list = [\"-m\", \"lmqg/t5-large-squad-qag\", \"-e\", \"./weird_dir\", \"-d\", \"./test_pipeline2.csv\", \"-l\", \"en\"]\n",
    "df = run_evaluation(args_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
